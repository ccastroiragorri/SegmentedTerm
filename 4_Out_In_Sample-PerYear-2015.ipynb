{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ccastro\\lib\\site-packages\\statsmodels\\compat\\pandas.py:56: FutureWarning: The pandas.core.datetools module is deprecated and will be removed in a future version. Please use the pandas.tseries module instead.\n",
      "  from pandas.core import datetools\n"
     ]
    }
   ],
   "source": [
    "### Se importan las librerias\n",
    "import os \n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import pickle\n",
    "from numpy import exp\n",
    "import sys\n",
    "sys.path.append('libreriasTesis')\n",
    "from sklearn.linear_model import LinearRegression\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.patches as mpatches\n",
    "from statsmodels.tsa.api import VAR\n",
    "pd.options.display.max_rows = 999\n",
    "pd.options.display.max_columns = 999\n",
    "from IPython.display import clear_output, Image, display\n",
    "### Se asingan los paths\n",
    "pathTesis = os.getcwd()\n",
    "pathBases = os.path.join(pathTesis,'bases/ndatos')\n",
    "pathGraficas = os.path.join(pathTesis,'GraficasN')\n",
    "pathForec = os.path.join(pathTesis,'bases/forecast')\n",
    "pathTables = os.path.join(pathTesis,'tables')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "year_t=2015\n",
    "year_t_1=2014"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "### Se lee la data y se cambian los nombres\n",
    "dataTotalC = pd.read_csv(os.path.join(pathBases,str(year_t)+'data.csv'), sep='|',index_col=['Fecha'], parse_dates=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "##Drop nans column\n",
    "dataTotal=dataTotalC.dropna(axis=1,how='all')\n",
    "dataTotal=dataTotal.dropna(axis=0,how='any')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0.004</th>\n",
       "      <th>0.1</th>\n",
       "      <th>0.3</th>\n",
       "      <th>1.5</th>\n",
       "      <th>1.5.1</th>\n",
       "      <th>3.8</th>\n",
       "      <th>3.9</th>\n",
       "      <th>4.7</th>\n",
       "      <th>5.6</th>\n",
       "      <th>7.3</th>\n",
       "      <th>9.6</th>\n",
       "      <th>11.7</th>\n",
       "      <th>13.3</th>\n",
       "      <th>15.7</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Fecha</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2015-01-14</th>\n",
       "      <td>4.363</td>\n",
       "      <td>4.360</td>\n",
       "      <td>4.365</td>\n",
       "      <td>4.98</td>\n",
       "      <td>5.00</td>\n",
       "      <td>5.96</td>\n",
       "      <td>5.61</td>\n",
       "      <td>5.86</td>\n",
       "      <td>6.15</td>\n",
       "      <td>6.64</td>\n",
       "      <td>7.04</td>\n",
       "      <td>7.14</td>\n",
       "      <td>7.28</td>\n",
       "      <td>7.54</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2015-01-15</th>\n",
       "      <td>4.358</td>\n",
       "      <td>4.358</td>\n",
       "      <td>4.363</td>\n",
       "      <td>4.85</td>\n",
       "      <td>4.93</td>\n",
       "      <td>5.75</td>\n",
       "      <td>5.48</td>\n",
       "      <td>5.76</td>\n",
       "      <td>6.05</td>\n",
       "      <td>6.56</td>\n",
       "      <td>6.93</td>\n",
       "      <td>7.07</td>\n",
       "      <td>7.18</td>\n",
       "      <td>7.45</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2015-01-16</th>\n",
       "      <td>4.350</td>\n",
       "      <td>4.360</td>\n",
       "      <td>4.363</td>\n",
       "      <td>4.81</td>\n",
       "      <td>4.90</td>\n",
       "      <td>5.66</td>\n",
       "      <td>5.39</td>\n",
       "      <td>5.67</td>\n",
       "      <td>5.98</td>\n",
       "      <td>6.55</td>\n",
       "      <td>6.88</td>\n",
       "      <td>7.02</td>\n",
       "      <td>7.13</td>\n",
       "      <td>7.41</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2015-01-17</th>\n",
       "      <td>4.350</td>\n",
       "      <td>4.360</td>\n",
       "      <td>4.363</td>\n",
       "      <td>4.81</td>\n",
       "      <td>4.90</td>\n",
       "      <td>5.66</td>\n",
       "      <td>5.39</td>\n",
       "      <td>5.67</td>\n",
       "      <td>5.98</td>\n",
       "      <td>6.55</td>\n",
       "      <td>6.88</td>\n",
       "      <td>7.02</td>\n",
       "      <td>7.13</td>\n",
       "      <td>7.41</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2015-01-18</th>\n",
       "      <td>4.350</td>\n",
       "      <td>4.360</td>\n",
       "      <td>4.363</td>\n",
       "      <td>4.81</td>\n",
       "      <td>4.90</td>\n",
       "      <td>5.66</td>\n",
       "      <td>5.39</td>\n",
       "      <td>5.67</td>\n",
       "      <td>5.98</td>\n",
       "      <td>6.55</td>\n",
       "      <td>6.88</td>\n",
       "      <td>7.02</td>\n",
       "      <td>7.13</td>\n",
       "      <td>7.41</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            0.004    0.1    0.3   1.5  1.5.1   3.8   3.9   4.7   5.6   7.3  \\\n",
       "Fecha                                                                        \n",
       "2015-01-14  4.363  4.360  4.365  4.98   5.00  5.96  5.61  5.86  6.15  6.64   \n",
       "2015-01-15  4.358  4.358  4.363  4.85   4.93  5.75  5.48  5.76  6.05  6.56   \n",
       "2015-01-16  4.350  4.360  4.363  4.81   4.90  5.66  5.39  5.67  5.98  6.55   \n",
       "2015-01-17  4.350  4.360  4.363  4.81   4.90  5.66  5.39  5.67  5.98  6.55   \n",
       "2015-01-18  4.350  4.360  4.363  4.81   4.90  5.66  5.39  5.67  5.98  6.55   \n",
       "\n",
       "             9.6  11.7  13.3  15.7  \n",
       "Fecha                               \n",
       "2015-01-14  7.04  7.14  7.28  7.54  \n",
       "2015-01-15  6.93  7.07  7.18  7.45  \n",
       "2015-01-16  6.88  7.02  7.13  7.41  \n",
       "2015-01-17  6.88  7.02  7.13  7.41  \n",
       "2015-01-18  6.88  7.02  7.13  7.41  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dimension:(352, 14)\n"
     ]
    }
   ],
   "source": [
    "display(dataTotal.head())\n",
    "print(\"dimension:{}\".format(dataTotal.shape))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dimension:(352, 13)\n"
     ]
    }
   ],
   "source": [
    "dataTotal=dataTotal.drop('1.5.1', axis=1)\n",
    "print(\"dimension:{}\".format(dataTotal.shape))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "### Se Asignan los diccionarios corresponientes a la data\n",
    "vencimientos=list(map(lambda x: float(x),list(dataTotal.columns.values)))\n",
    "observadosY = dict(zip(dataTotal.columns, vencimientos))\n",
    "### Segmentos\n",
    "corto=4\n",
    "mediano=9\n",
    "cortoPlazoM=vencimientos[:corto]\n",
    "medianoPlazoM=vencimientos[corto:mediano]\n",
    "largoPlazoM=vencimientos[mediano:]\n",
    "cortoPlazoY = dict(zip(dataTotal.columns[:corto], cortoPlazoM))\n",
    "medianoPlazoY = dict(zip(dataTotal.columns[corto:mediano], medianoPlazoM))\n",
    "largoPlazoY = dict(zip(dataTotal.columns[mediano:], largoPlazoM))\n",
    "innerY = {'1.6':1.6, '8':8}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Estimation\n",
    "lm = LinearRegression()\n",
    "lm_no_intercept=LinearRegression(fit_intercept=False) #include or remove the intercept"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Se empieza a calculcar por separado los factores corresponientes a los modelos clasicos, segmentado y fuertemente segmentado"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ----------------------------------------------"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Nelson Siegel Clasico"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "### Los factores del modelo clasico con un lambda de 0.0609\n",
    "def g(term,lambDa = 0.0609):\n",
    "    resultado = (1 - exp(-lambDa*term)) / (lambDa*term)\n",
    "    return resultado\n",
    "def h(term,lambDa = 0.0609):\n",
    "    resultado = ((1 - exp(-lambDa*term)) / (lambDa*term)) - exp(-lambDa*term)\n",
    "    return resultado"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def NS_clasico(data,terms):\n",
    "    ### Se calcula el vector para los distinitos vencimientos\n",
    "    gNS = g(np.array(terms))\n",
    "    hNS = h(np.array(terms)) \n",
    "    X = pd.DataFrame({'x2':gNS,'x3':hNS}).values\n",
    "    NS_fit=lm.fit(X,data.values.transpose())\n",
    "    coefs=np.concatenate((np.array(NS_fit.intercept_.tolist()),NS_fit.coef_[:,0],NS_fit.coef_[:,1]),axis=0).reshape((3,data.values.shape[0])).transpose()\n",
    "    betas_NS = pd.DataFrame(coefs, index=data.index,columns=[\"a\",\"b\",\"c\"])\n",
    "    ### Yields Estimados In-sample\n",
    "    fitted_yield_NS = pd.DataFrame(NS_fit.predict(X).transpose(), index=data.index,columns=data.columns)    \n",
    "    #RMSE\n",
    "    NS3 = (pd.DataFrame(np.sqrt((data.values - fitted_yield_NS.values)**2)).apply(np.mean,0)*100).values\n",
    "    RMSE_NS3=pd.Series(NS3,index=data.columns)\n",
    "    out=(betas_NS,fitted_yield_NS,RMSE_NS3)\n",
    "    return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "(betas_NS,fitted_yield_NS,RMSE_NS3)=NS_clasico(dataTotal,vencimientos)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "betas_NS.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "fitted_yield_NS.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Observed Yields\n",
    "dataTotal.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ----------------------------------------------"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Segmented Models\n",
    "factores_seg=[\"a^I\",\"b^I\",\"c^I\",\"a^II\",\"b^II\",\"c^II\",\"a^III\",\"b^III\",\"c^III\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Nelson Siegel Segmented Non-Smootheness, prefered habitat model Vayanos and Vila (2009)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def NS_seg_Phabit(data,terms,corto,mediano,factores_seg):\n",
    "    ### Se calcula el vector para los distinitos vencimientos\n",
    "    gNS = g(np.array(terms))\n",
    "    hNS = h(np.array(terms)) \n",
    "    X = pd.DataFrame({'x2':gNS,'x3':hNS}).values\n",
    "    NS_fit_corto=lm.fit(X[:corto,:],data.iloc[:,:corto].values.transpose())\n",
    "    NS_fit_mediano=lm.fit(X[corto:mediano,:],data.iloc[:,corto:mediano].values.transpose())\n",
    "    NS_fit_largo=lm.fit(X[mediano:,:],data.iloc[:,mediano:].values.transpose())\n",
    "    coefs_corto=np.concatenate((np.array(NS_fit_corto.intercept_.tolist()),NS_fit_corto.coef_[:,0],NS_fit_corto.coef_[:,1]),axis=0).reshape((3,data.values.shape[0])).transpose()\n",
    "    coefs_mediano=np.concatenate((np.array(NS_fit_mediano.intercept_.tolist()),NS_fit_mediano.coef_[:,0],NS_fit_mediano.coef_[:,1]),axis=0).reshape((3,data.values.shape[0])).transpose()\n",
    "    coefs_largo=np.concatenate((np.array(NS_fit_largo.intercept_.tolist()),NS_fit_largo.coef_[:,0],NS_fit_largo.coef_[:,1]),axis=0).reshape((3,data.values.shape[0])).transpose()\n",
    "    betas_NS_seg_nosmooth = pd.DataFrame(np.concatenate((coefs_corto,coefs_mediano,coefs_largo),axis=1), index=data.index,columns=factores_seg)    \n",
    "    ### Yields Estimados In-sample\n",
    "    fited_yield_seg_nosmooth=np.concatenate((NS_fit_corto.predict(X[:corto,:]).transpose(),NS_fit_mediano.predict(X[corto:mediano,:]).transpose(),NS_fit_largo.predict(X[mediano:,:]).transpose()),axis=1)\n",
    "    fitted_yield_NS_seg_nosmooth = pd.DataFrame(fited_yield_seg_nosmooth, index=data.index,columns=data.columns)\n",
    "    #RMSE\n",
    "    NS3_seg_nosmooth = (pd.DataFrame(np.sqrt((data.values - fitted_yield_NS_seg_nosmooth.values)**2)).apply(np.mean,0)*100).values\n",
    "    RMSE_NS3_seg_nosmooth=pd.Series(NS3_seg_nosmooth,index=data.columns)\n",
    "    out=(betas_NS_seg_nosmooth,fitted_yield_NS_seg_nosmooth,RMSE_NS3_seg_nosmooth)\n",
    "    return out    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "(betas_NS_seg_nosmooth,fitted_yield_NS_seg_nosmooth,RMSE_NS3_seg_nosmooth)=NS_seg_Phabit(dataTotal,vencimientos,corto,mediano,factores_seg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "betas_NS_seg_nosmooth.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "fitted_yield_NS_seg_nosmooth.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Observed Yields\n",
    "dataTotal.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of observed terms:13\n",
      "Number of factors:9\n"
     ]
    }
   ],
   "source": [
    "print(\"Number of observed terms:{}\".format(fitted_yield_NS_seg_nosmooth.columns.size))\n",
    "print(\"Number of factors:{}\".format(betas_NS_seg_nosmooth.columns.size))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ----------------------------------------------"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Knots for Segments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Introduce unobservable inner knots\n",
    "Uobknots=('1.6','8')\n",
    "cortoPlazoY.update({'1.6':1.6})\n",
    "medianoPlazoY.update(innerY)\n",
    "largoPlazoY.update({'8':8})\n",
    "#introduce external knots\n",
    "innerY.update( {'0.004':0.004,'15.3':15.3} )\n",
    "#generalize\n",
    "#dataTotal.columns[0],dataTotal.columns[(dataTotal.columns.size-1)]\n",
    "#vencimientos[0],vencimientos[(len(vencimientos)-1)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "vec0 = lambda x: list(np.repeat(0,x))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Nelson Siegel Segmented, impose smoothness by restrictions on the estimated coefficients"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "### Se crean las funciones de los factores y sus derivadas de nelson y siegel para el modelo Segmentado suave\n",
    "def g(term,lambDa = 0.0609):\n",
    "    resultado = (1 - exp(-lambDa*term)) / (lambDa*term)\n",
    "    return resultado\n",
    "\n",
    "def gPD(term,lambDa = 0.0609):\n",
    "    resultado = (exp(-lambDa*term) * (lambDa*term + 1)) / (lambDa*(term ** 2))\n",
    "    return resultado\n",
    "\n",
    "def gSD(term,lambDa = 0.0609):\n",
    "    resultado = (2 - exp(-lambDa*term) * (((lambDa * term) ** 2) + 2*(lambDa*term + 1))) / (lambDa * (term ** 3))\n",
    "    return resultado \n",
    "\n",
    "def h(term,lambDa = 0.0609):\n",
    "    resultado = ((1 - exp(-lambDa*term)) / (lambDa*term)) - exp(-lambDa*term)\n",
    "    return resultado\n",
    "\n",
    "def hPD(term,lambDa = 0.0609):\n",
    "    resultado = (exp(-lambDa*term) * (((lambDa*term) ** 2) + (lambDa*term) + 1) - 1) / (lambDa*(term ** 2))\n",
    "    return resultado\n",
    "\n",
    "def hSD(term,lambDa = 0.0609):\n",
    "    resultado = (2 - exp(-lambDa*term)*(((lambDa*term) ** 3) + ((lambDa*term) ** 2) + 2*(lambDa*term + 1))) / (lambDa * (term ** 3))\n",
    "    return resultado\n",
    "\n",
    "\n",
    "### Se crea la funcion X que permite retornar los vector de longitud 3 para la creacion de las matrices necesarias \n",
    "### del modelo segmentado\n",
    "\n",
    "\n",
    "def X_function(tao,corte,signo,derivada):\n",
    "    if derivada == '':\n",
    "        if signo == '+':\n",
    "            if corte == 'Corto':\n",
    "                return [1, g(cortoPlazoY[tao]),h(cortoPlazoY[tao])]\n",
    "            elif corte == 'Mediano':\n",
    "                return [1, g(medianoPlazoY[tao]),h(medianoPlazoY[tao])]\n",
    "            elif corte == 'Largo':\n",
    "                return [1, g(largoPlazoY[tao]),h(largoPlazoY[tao])]\n",
    "        elif signo == '-':\n",
    "            if corte == 'Corto':\n",
    "                return [-1, -g(cortoPlazoY[tao]),-h(cortoPlazoY[tao])]\n",
    "            elif corte == 'Mediano':\n",
    "                return [-1, -g(medianoPlazoY[tao]),-h(medianoPlazoY[tao])]\n",
    "            elif corte == 'Largo':\n",
    "                return [-1, -g(largoPlazoY[tao]),-h(largoPlazoY[tao])]\n",
    "    elif derivada == 'PD':\n",
    "        if signo == '+':\n",
    "            if corte == 'Corto':\n",
    "                return [0, gPD(cortoPlazoY[tao]),hPD(cortoPlazoY[tao])]\n",
    "            elif corte == 'Mediano':\n",
    "                return [0, gPD(medianoPlazoY[tao]),hPD(medianoPlazoY[tao])]\n",
    "            elif corte == 'Largo':\n",
    "                return [0, gPD(largoPlazoY[tao]),hPD(largoPlazoY[tao])]\n",
    "        elif signo == '-':\n",
    "            if corte == 'Corto':\n",
    "                return [0, -gPD(cortoPlazoY[tao]),-hPD(cortoPlazoY[tao])]\n",
    "            elif corte == 'Mediano':\n",
    "                return [0, -gPD(medianoPlazoY[tao]),-hPD(medianoPlazoY[tao])]\n",
    "            elif corte == 'Largo':\n",
    "                return [0, -gPD(largoPlazoY[tao]),-hPD(largoPlazoY[tao])]\n",
    "    elif derivada == 'SD':\n",
    "        if signo == '+':\n",
    "            if corte == 'Corto':\n",
    "                return [0, gSD(cortoPlazoY[tao]),hSD(cortoPlazoY[tao])]\n",
    "            elif corte == 'Mediano':\n",
    "                return [0, gSD(medianoPlazoY[tao]),hSD(medianoPlazoY[tao])]\n",
    "            elif corte == 'Largo':\n",
    "                return [0, gSD(largoPlazoY[tao]),hSD(largoPlazoY[tao])]\n",
    "        elif signo == '-':\n",
    "            if corte == 'Corto':\n",
    "                return [0, -gSD(cortoPlazoY[tao]),-hSD(cortoPlazoY[tao])]\n",
    "            elif corte == 'Mediano':\n",
    "                return [0, -gSD(medianoPlazoY[tao]),-hSD(medianoPlazoY[tao])]\n",
    "            elif corte == 'Largo':\n",
    "                return [0, -gSD(largoPlazoY[tao]),-hSD(largoPlazoY[tao])]\n",
    "            "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Aplicacion empirica\n",
    "\n",
    "De aqui en adelante se crean las matrices necesarias w2, w1, R1, R2 para la creacion de Z.\n",
    "Lo unico que cambia son los vencimientos de w1 y w2 y los valores de los yields"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dimension:(5, 5)\n"
     ]
    }
   ],
   "source": [
    "#R1\n",
    "#complete matrix \n",
    "#NOTE the first line in matrix can be modified refering to refear to the first observable yield \n",
    "#this implies also a change in R2\n",
    "R1_c =  np.matrix([X_function('1.6','Corto','+','')+ X_function('1.6','Mediano','-',''),\n",
    "                   vec0(3)+X_function('8','Mediano','+',''),\n",
    "                   X_function('1.6','Corto','+','PD')+ X_function('1.6','Mediano','-','PD'),\n",
    "                   vec0(3)+X_function('8','Mediano','+','PD'),\n",
    "                   X_function('1.6','Corto','+','SD')+ X_function('1.6','Mediano','-','SD')])\n",
    "#truncate to make symetric\n",
    "R1=R1_c[:,0:(R1_c.shape[1]-1)]\n",
    "print(\"dimension:{}\".format(R1.shape))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dimension:(5, 4)\n"
     ]
    }
   ],
   "source": [
    "#R2\n",
    "#complete matrix  \n",
    "#NOTE that the last line in matrix is the only one refering to an last observable yield (important to change for different year)\n",
    "R2_c =  np.matrix([X_function('1.6','Mediano','-','')+vec0(3),\n",
    "                 X_function('8','Mediano','+','')+ X_function('8','Largo','-',''),\n",
    "                 X_function('1.6','Mediano','-','PD')+ vec0(3),\n",
    "                 X_function('8','Mediano','+','PD')+ X_function('8','Largo','-','PD'),\n",
    "                 X_function('1.6','Mediano','-','SD')+vec0(3)])\n",
    "#truncate to make symetric\n",
    "R2=R2_c[:,2:]\n",
    "print(\"dimension:{}\".format(R2.shape))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dimension W:(13, 9)\n",
      "dimension W2:(13, 5)\n",
      "dimension W1:(13, 4)\n"
     ]
    }
   ],
   "source": [
    "#W matrix complete\n",
    "W =  np.matrix([X_function('0.004','Corto','+','')+vec0(6),\n",
    "                X_function('0.1','Corto','+','')+vec0(6),\n",
    "                X_function('0.3','Corto','+','')+vec0(6),\n",
    "                X_function('1.5','Corto','+','')+vec0(6),\n",
    "                vec0(3) + X_function('3.8','Mediano','+','')+vec0(3),\n",
    "                vec0(3) + X_function('3.9','Mediano','+','')+vec0(3),\n",
    "                vec0(3) + X_function('4.7','Mediano','+','')+vec0(3),\n",
    "                vec0(3) + X_function('5.6','Mediano','+','')+vec0(3),\n",
    "                vec0(3) + X_function('7.3','Mediano','+','')+vec0(3),\n",
    "                vec0(6) + X_function('9.6','Largo','+',''),\n",
    "                vec0(6) + X_function('11.7','Largo','+',''),\n",
    "                vec0(6) + X_function('13.3','Largo','+',''),\n",
    "                vec0(6) + X_function('15.7','Largo','+','')])\n",
    "print(\"dimension W:{}\".format(W.shape))\n",
    "W2=W[:,0:5]\n",
    "print(\"dimension W2:{}\".format(W2.shape))\n",
    "W1=W[:,5:W.shape[1]]\n",
    "print(\"dimension W1:{}\".format(W1.shape))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dimension W knots:(2, 9)\n",
      "dimension W2k:(2, 5)\n",
      "dimension W1k:(2, 4)\n"
     ]
    }
   ],
   "source": [
    "#W matrix complete for estimating the unobserved yields\n",
    "Wk =  np.matrix([X_function('1.6','Corto','+','')+vec0(6),\n",
    "                vec0(3) + X_function('8','Mediano','+','')+vec0(3)])\n",
    "#Wk =  np.matrix([vec0(3) + X_function('1.6','Mediano','+','')+vec0(3),\n",
    "#                vec0(6) + X_function('8','Largo','+','')])\n",
    "print(\"dimension W knots:{}\".format(Wk.shape))\n",
    "W2k=Wk[:,0:5]\n",
    "print(\"dimension W2k:{}\".format(W2k.shape))\n",
    "W1k=Wk[:,5:W.shape[1]]\n",
    "print(\"dimension W1k:{}\".format(W1k.shape))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def NS_seg_weak(data,corto,mediano,R1,R2,W1,W2,W1k,W2k,factores_seg,Uobknots):\n",
    "    R1_invertida = np.linalg.inv(R1)\n",
    "    Z = W1 - (W2 * R1_invertida * R2)\n",
    "    #print(\"dimension Z:{}\".format(Z.shape))\n",
    "    #estimation of the restricted factors for \"c^II\",\"a^III\",\"b^III\",\"c^III\"\n",
    "    NS_Seg_M_L=lm_no_intercept.fit(Z,data.values.transpose())\n",
    "    #use equation from the paper to obtain factors #\"a^I\",\"b^I\",\"c^I\",\"a^II\",\"b^II\"\n",
    "    coefs_S_M=(-R1_invertida*R2*NS_Seg_M_L.coef_.transpose()).transpose()\n",
    "    betas_NS_seg_smooth = pd.DataFrame(np.concatenate((coefs_S_M,NS_Seg_M_L.coef_),axis=1), index=data.index,columns=factores_seg)\n",
    "    ### Yields Estimados In-sample\n",
    "    fitted_yield_NS_seg_smooth_z = pd.DataFrame(NS_Seg_M_L.predict(Z).transpose(), index=data.index,columns=data.columns)\n",
    "    #RMSE\n",
    "    NS3_seg_smooth = (pd.DataFrame(np.sqrt((data.values - fitted_yield_NS_seg_smooth_z.values)**2)).apply(np.mean,0)*100).values\n",
    "    RMSE_NS3_seg_smooth=pd.Series(NS3_seg_smooth,index=data.columns)\n",
    "    #Latent Yields\n",
    "    Zk = W1k - (W2k * R1_invertida * R2)\n",
    "    #print(\"dimension Z knots:{}\".format(Zk.shape))\n",
    "    ZZ_invertida = np.linalg.inv(Z.transpose()*Z)\n",
    "    fit_yield_latent=(Zk*ZZ_invertida*Z.transpose()*data.values.transpose()).transpose()\n",
    "    fitted_yield_latent = pd.DataFrame(fit_yield_latent, index=data.index,columns=Uobknots)\n",
    "    #Add Latent Yields\n",
    "    short=fitted_yield_NS_seg_smooth_z.iloc[:,:corto]\n",
    "    knotSM=fitted_yield_latent.iloc[:,0]\n",
    "    medium=fitted_yield_NS_seg_smooth_z.iloc[:,corto:mediano]\n",
    "    knotML=fitted_yield_latent.iloc[:,1]\n",
    "    long=fitted_yield_NS_seg_smooth_z.iloc[:,mediano:]\n",
    "    frames = [short, knotSM, medium,knotML,long]\n",
    "    fitted_yields_NS_seg_weak= pd.concat(frames,axis=1)\n",
    "    out=(betas_NS_seg_smooth,fitted_yields_NS_seg_weak,RMSE_NS3_seg_smooth)\n",
    "    return out       "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "(betas_NS_seg_smooth,fitted_yield_NS_seg_weak,RMSE_NS3_seg_smooth)=NS_seg_weak(dataTotal,corto,mediano,R1,R2,W1,W2,W1k,W2k,factores_seg,Uobknots)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "betas_NS_seg_smooth.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Observed Yields\n",
    "dataTotal.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "fitted_yield_NS_seg_weak.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ----------------------------------------------"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Nelson Siegel Strongly Segmented"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "### Se crean las funciones de los factores y sus derivadas de nelson y siegel para el modelo Segmentado Fuertemente\n",
    "### Segmentado\n",
    "\n",
    "def gs(term,termImenos,lambDa = 0.0609, p = 0.5):\n",
    "    A = term - termImenos*(1-p)\n",
    "    resultado = (1 - exp(-lambDa*A)) / (lambDa*A)\n",
    "    return resultado\n",
    "\n",
    "def gPDs(term,termImenos,lambDa = 0.0609, p = 0.5):\n",
    "    A = term - termImenos*(1-p)\n",
    "    resultado = (exp(-lambDa*A) * (lambDa*A + 1)) / (lambDa*(A ** 2))\n",
    "    return resultado\n",
    "\n",
    "def gSDs(term,termImenos,lambDa = 0.0609, p = 0.5):\n",
    "    A = term - termImenos*(1-p)\n",
    "    resultado = (2 - exp(-lambDa*A) * (((lambDa * A) ** 2) + 2*(lambDa*A + 1))) / (lambDa * (A ** 3))\n",
    "    return resultado \n",
    "\n",
    "def hs(term,termImenos,lambDa = 0.0609, p = 0.5):\n",
    "    A = term - termImenos*(1-p)\n",
    "    resultado = ((1 - exp(-lambDa*A)) / (lambDa*A)) - exp(-lambDa*A)\n",
    "    return resultado\n",
    "\n",
    "def hPDs(term,termImenos,lambDa = 0.0609, p = 0.5):\n",
    "    A = term - termImenos*(1-p)\n",
    "    resultado = (exp(-lambDa*A) * (((lambDa*A) ** 2) + (lambDa*A) + 1) - 1) / (lambDa*(A ** 2))\n",
    "    return resultado\n",
    "\n",
    "def hSDs(term,termImenos,lambDa = 0.0609, p = 0.5):\n",
    "    A = term - termImenos*(1-p)\n",
    "    resultado = (2 - exp(-lambDa*A)*(((lambDa*A) ** 3) + ((lambDa*A) ** 2) + 2*(lambDa*A + 1))) / (lambDa * (A ** 3))\n",
    "    return resultado\n",
    "\n",
    "\n",
    "### Se crea la funcion X que permite retornar los vector de longitud 3 para la creacion de las matrices necesarias \n",
    "### del modelo fuertemente segmentado\n",
    "\n",
    "def Xs_function(tao,taoImenos,corte,signo,derivada):\n",
    "    if derivada == '':\n",
    "        if signo == '+':\n",
    "            if corte == 'Corto':\n",
    "                return [1, gs(cortoPlazoY[tao],cortoPlazoY[taoImenos]),hs(cortoPlazoY[tao],cortoPlazoY[taoImenos])]\n",
    "            elif corte == 'Mediano':\n",
    "                return [1, gs(medianoPlazoY[tao],medianoPlazoY[taoImenos]),hs(medianoPlazoY[tao],medianoPlazoY[taoImenos])]\n",
    "            elif corte == 'Largo':\n",
    "                return [1, gs(largoPlazoY[tao],largoPlazoY[taoImenos]),hs(largoPlazoY[tao],largoPlazoY[taoImenos])]\n",
    "        elif signo == '-':\n",
    "            if corte == 'Corto':\n",
    "                return [-1, -gs(cortoPlazoY[tao],cortoPlazoY[taoImenos]),-hs(cortoPlazoY[tao],cortoPlazoY[taoImenos])]\n",
    "            elif corte == 'Mediano':\n",
    "                return [-1, -gs(medianoPlazoY[tao],medianoPlazoY[taoImenos]),-hs(medianoPlazoY[tao],medianoPlazoY[taoImenos])]\n",
    "            elif corte == 'Largo':\n",
    "                return [-1, -gs(largoPlazoY[tao],largoPlazoY[taoImenos]),-hs(largoPlazoY[tao],largoPlazoY[taoImenos])]\n",
    "    elif derivada == 'PD':\n",
    "        if signo == '+':\n",
    "            if corte == 'Corto':\n",
    "                return [0, gPDs(cortoPlazoY[tao],cortoPlazoY[taoImenos]),hPDs(cortoPlazoY[tao],cortoPlazoY[taoImenos])]\n",
    "            elif corte == 'Mediano':\n",
    "                return [0, gPDs(medianoPlazoY[tao],medianoPlazoY[taoImenos]),hPDs(medianoPlazoY[tao],medianoPlazoY[taoImenos])]\n",
    "            elif corte == 'Largo':\n",
    "                return [0, gPDs(largoPlazoY[tao],largoPlazoY[taoImenos]),hPDs(largoPlazoY[tao],largoPlazoY[taoImenos])]\n",
    "        elif signo == '-':\n",
    "            if corte == 'Corto':\n",
    "                return [0, -gPDs(cortoPlazoY[tao],cortoPlazoY[taoImenos]),-hPDs(cortoPlazoY[tao],cortoPlazoY[taoImenos])]\n",
    "            elif corte == 'Mediano':\n",
    "                return [0, -gPDs(medianoPlazoY[tao],medianoPlazoY[taoImenos]),-hPDs(medianoPlazoY[tao],medianoPlazoY[taoImenos])]\n",
    "            elif corte == 'Largo':\n",
    "                return [0, -gPDs(largoPlazoY[tao],largoPlazoY[taoImenos]),-hPDs(largoPlazoY[tao],largoPlazoY[taoImenos])]\n",
    "    elif derivada == 'SD':\n",
    "        if signo == '+':\n",
    "            if corte == 'Corto':\n",
    "                return [0, gSDs(cortoPlazoY[tao],cortoPlazoY[taoImenos]),hSDs(cortoPlazoY[tao],cortoPlazoY[taoImenos])]\n",
    "            elif corte == 'Mediano':\n",
    "                return [0, gSDs(medianoPlazoY[tao],medianoPlazoY[taoImenos]),hSDs(medianoPlazoY[tao],medianoPlazoY[taoImenos])]\n",
    "            elif corte == 'Largo':\n",
    "                return [0, gSDs(largoPlazoY[tao],largoPlazoY[taoImenos]),hSDs(largoPlazoY[tao],largoPlazoY[taoImenos])]\n",
    "        elif signo == '-':\n",
    "            if corte == 'Corto':\n",
    "                return [0, -gSDs(cortoPlazoY[tao],cortoPlazoY[taoImenos]),-hSDs(cortoPlazoY[tao],cortoPlazoY[taoImenos])]\n",
    "            elif corte == 'Mediano':\n",
    "                return [0, -gSDs(medianoPlazoY[tao],medianoPlazoY[taoImenos]),-hSDs(medianoPlazoY[tao],medianoPlazoY[taoImenos])]\n",
    "            elif corte == 'Largo':\n",
    "                return [0, -gSDs(largoPlazoY[tao],largoPlazoY[taoImenos]),-hSDs(largoPlazoY[tao],largoPlazoY[taoImenos])]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Aplicacion empirica\n",
    "\n",
    "De aqui en adelante se crean las matrices necesarias w2, w1, R1, R2 para la creacion de Z.\n",
    "Lo unico que cambia son los vencimientos de w1 y w2 y los valores de los yields"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dimension:(5, 5)\n"
     ]
    }
   ],
   "source": [
    "#R1\n",
    "#complete matrix \n",
    "#NOTE the first line in matrix can be modified refering to refear to the first observable yield \n",
    "#this implies also a change in R2\n",
    "R1_c =  np.matrix([Xs_function('1.6','0.004','Corto','+','')+ Xs_function('1.6','1.6','Mediano','-',''),\n",
    "                   vec0(3)+Xs_function('8','1.6','Mediano','+',''),\n",
    "                   Xs_function('1.6','0.004','Corto','+','PD')+ Xs_function('1.6','1.6','Mediano','-','PD'),\n",
    "                   vec0(3)+Xs_function('8','1.6','Mediano','+','PD'),\n",
    "                   Xs_function('1.6','0.004','Corto','+','SD')+ Xs_function('1.6','1.6','Mediano','-','SD')])\n",
    "#truncate to make symetric\n",
    "R1=R1_c[:,0:(R1_c.shape[1]-1)]\n",
    "R1_invertida = np.linalg.inv(R1)\n",
    "print(\"dimension:{}\".format(R1.shape))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dimension:(5, 4)\n"
     ]
    }
   ],
   "source": [
    "#R2\n",
    "#complete matrix  \n",
    "#NOTE that the last line in matrix is the only one refering to an last observable yield (important to change for different year)\n",
    "R2_c =  np.matrix([Xs_function('1.6','1.6','Mediano','-','')+vec0(3),\n",
    "                 Xs_function('8','1.6','Mediano','+','')+ Xs_function('8','8','Largo','-',''),\n",
    "                 Xs_function('1.6','1.6','Mediano','-','PD')+ vec0(3),\n",
    "                 Xs_function('8','1.6','Mediano','+','PD')+ Xs_function('8','8','Largo','-','PD'),\n",
    "                 Xs_function('1.6','1.6','Mediano','-','SD')+vec0(3)])\n",
    "#truncate to make symetric\n",
    "R2=R2_c[:,2:]\n",
    "print(\"dimension:{}\".format(R2.shape))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dimension W:(13, 9)\n",
      "dimension W2:(13, 5)\n",
      "dimension W1:(13, 4)\n"
     ]
    }
   ],
   "source": [
    "#W matrix complete\n",
    "W =  np.matrix([X_function('0.004','Corto','+','')+vec0(6),\n",
    "                X_function('0.1','Corto','+','')+vec0(6),\n",
    "                X_function('0.3','Corto','+','')+vec0(6),\n",
    "                X_function('1.5','Corto','+','')+vec0(6),\n",
    "                vec0(3) + X_function('3.8','Mediano','+','')+vec0(3),\n",
    "                vec0(3) + X_function('3.9','Mediano','+','')+vec0(3),\n",
    "                vec0(3) + X_function('4.7','Mediano','+','')+vec0(3),\n",
    "                vec0(3) + X_function('5.6','Mediano','+','')+vec0(3),\n",
    "                vec0(3) + X_function('7.3','Mediano','+','')+vec0(3),\n",
    "                vec0(6) + X_function('9.6','Largo','+',''),\n",
    "                vec0(6) + X_function('11.7','Largo','+',''),\n",
    "                vec0(6) + X_function('13.3','Largo','+',''),\n",
    "                vec0(6) + X_function('15.7','Largo','+','')])\n",
    "print(\"dimension W:{}\".format(W.shape))\n",
    "W2=W[:,0:5]\n",
    "print(\"dimension W2:{}\".format(W2.shape))\n",
    "W1=W[:,5:W.shape[1]]\n",
    "print(\"dimension W1:{}\".format(W1.shape))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dimension W knots:(2, 9)\n",
      "dimension W2k:(2, 5)\n",
      "dimension W1k:(2, 4)\n"
     ]
    }
   ],
   "source": [
    "#W matrix complete for estimating the unobserved yields\n",
    "Wk =  np.matrix([Xs_function('1.6','0.004','Corto','+','')+vec0(6),\n",
    "                vec0(3) + Xs_function('8','1.6','Mediano','+','')+vec0(3)])\n",
    "#Wk =  np.matrix([vec0(3) + Xs_function('1.6','1.6','Mediano','+','')+vec0(3),\n",
    "#                vec0(6) + Xs_function('8','8','Largo','+','')])\n",
    "print(\"dimension W knots:{}\".format(Wk.shape))\n",
    "W2k=Wk[:,0:5]\n",
    "print(\"dimension W2k:{}\".format(W2k.shape))\n",
    "W1k=Wk[:,5:W.shape[1]]\n",
    "print(\"dimension W1k:{}\".format(W1k.shape))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def NS_seg_strong(data,corto,mediano,R1,R2,W1,W2,W1k,W2k,factores_seg,Uobknots):\n",
    "    R1_invertida = np.linalg.inv(R1)\n",
    "    Z = W1 - (W2 * R1_invertida * R2)\n",
    "    #estimation of the restricted factors for \"c^II\",\"a^III\",\"b^III\",\"c^III\"\n",
    "    NS_Seg_M_L=lm_no_intercept.fit(Z,data.values.transpose())\n",
    "    #use equation from the paper to obtain factors #\"a^I\",\"b^I\",\"c^I\",\"a^II\",\"b^II\"\n",
    "    coefs_S_M=(-R1_invertida*R2*NS_Seg_M_L.coef_.transpose()).transpose()\n",
    "    betas_NS_seg_smooth_s = pd.DataFrame(np.concatenate((coefs_S_M,NS_Seg_M_L.coef_),axis=1), index=data.index,columns=factores_seg)\n",
    "    ### Yields Estimados In-sample\n",
    "    fitted_yield_NS_seg_smooth_s_z = pd.DataFrame(NS_Seg_M_L.predict(Z).transpose(), index=data.index,columns=data.columns)\n",
    "    #RMSE\n",
    "    NS3_seg_smooth_s = (pd.DataFrame(np.sqrt((data.values - fitted_yield_NS_seg_smooth_s_z.values)**2)).apply(np.mean,0)*100).values\n",
    "    RMSE_NS3_seg_smooth_s=pd.Series(NS3_seg_smooth_s,index=data.columns)\n",
    "    Zk = W1k - (W2k * R1_invertida * R2)\n",
    "    #print(\"dimension Z knots:{}\".format(Zk.shape))\n",
    "    #Fitted latent yields\n",
    "    ZZ_invertida = np.linalg.inv(Z.transpose()*Z)\n",
    "    fit_yield_latent_s=(Zk*ZZ_invertida*Z.transpose()*data.values.transpose()).transpose()\n",
    "    fitted_yield_latent_s = pd.DataFrame(fit_yield_latent_s, index=data.index,columns=Uobknots)\n",
    "    #Add Latent Yields\n",
    "    short=fitted_yield_NS_seg_smooth_s_z.iloc[:,:corto]\n",
    "    knotSM=fitted_yield_latent_s.iloc[:,0]\n",
    "    medium=fitted_yield_NS_seg_smooth_s_z.iloc[:,corto:mediano]\n",
    "    knotML=fitted_yield_latent_s.iloc[:,1]\n",
    "    long=fitted_yield_NS_seg_smooth_s_z.iloc[:,mediano:]\n",
    "    frames = [short, knotSM, medium,knotML,long]\n",
    "    fitted_yields_NS_seg_strong= pd.concat(frames,axis=1)\n",
    "    out=(betas_NS_seg_smooth_s,fitted_yields_NS_seg_strong,RMSE_NS3_seg_smooth_s)\n",
    "    return out "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "(betas_NS_seg_smooth_s,fitted_yield_NS_seg_strong,RMSE_NS3_seg_smooth_s)=NS_seg_strong(dataTotal,corto,mediano,R1,R2,W1,W2,W1k,W2k,factores_seg,Uobknots)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "betas_NS_seg_smooth_s.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Observed Yields\n",
    "dataTotal.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "fitted_yield_NS_seg_strong.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ----------------------------------------------"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Graficas"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Loadings Segmentado"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def gG(term,lambDa = 0.0609):\n",
    "    resultado = (1 - exp(-lambDa*term)) / (lambDa*term)\n",
    "    return resultado\n",
    "\n",
    "\n",
    "def hG(term,lambDa = 0.0609):\n",
    "    resultado = ((1 - exp(-lambDa*term)) / (lambDa*term)) - exp(-lambDa*term)\n",
    "    return resultado\n",
    "\n",
    "maturityPaper = np.array(range(0,121))\n",
    "gValor = gG(maturityPaper)\n",
    "hValor = hG(maturityPaper)\n",
    "vec1 = list(np.repeat(1,len(maturityPaper)))\n",
    "grafica2 = pd.DataFrame.from_dict({'1':vec1,'g':gValor,'h':hValor})\n",
    "grafica2.plot()\n",
    "plt.xlabel('Maturity (Months)')\n",
    "plt.savefig(os.path.join(pathGraficas,'FactorLoadingsNS3'))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Loadings Segmentado Fuertemente"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def gsG(term,termImenos,lambDa = 0.0609, p = 0.5):\n",
    "    A = term - termImenos*(1-p)\n",
    "    resultado = (1 - exp(-lambDa*A)) / (lambDa*A)\n",
    "    return resultado\n",
    "\n",
    "def hsG(term,termImenos,lambDa = 0.0609, p = 0.5):\n",
    "    A = term - termImenos*(1-p)\n",
    "    resultado = ((1 - exp(-lambDa*A)) / (lambDa*A)) - exp(-lambDa*A)\n",
    "    return resultado\n",
    "\n",
    "maturityPaper1 = np.array(range(0,15))\n",
    "maturityPaper2 = np.array(range(16,54))\n",
    "maturityPaper3 = np.array(range(55,107))\n",
    "maturityPaper4 = np.array(range(108,120))\n",
    "\n",
    "gValor1 = gsG(maturityPaper1,0)\n",
    "gValor2 = gsG(maturityPaper2,16)\n",
    "gValor3 = gsG(maturityPaper3,55)\n",
    "gValor4 = gsG(maturityPaper4,108)\n",
    "gValor = np.append(np.append(gValor1,gValor2),np.append(gValor3,gValor4))\n",
    "\n",
    "hValor1 = hsG(maturityPaper1,0)\n",
    "hValor2 = hsG(maturityPaper2,16)\n",
    "hValor3 = hsG(maturityPaper3,55)\n",
    "hValor4 = hsG(maturityPaper4,108)\n",
    "hValor = np.append(np.append(hValor1,hValor2),np.append(hValor3,hValor4))\n",
    "\n",
    "vec1 = list(np.repeat(1,len(hValor)))\n",
    "\n",
    "grafica2 = pd.DataFrame.from_dict({'1':vec1,'g':gValor,'h':hValor})\n",
    "grafica2.plot()\n",
    "plt.axvline(x=16)\n",
    "plt.axvline(x=55)\n",
    "plt.axvline(x=108)\n",
    "plt.xlabel('Maturity (Months)')\n",
    "plt.savefig(os.path.join(pathGraficas,'FactorLoadingsNS3Strong'))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Observed Yields"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "dataTotal.index.names = ['Date']\n",
    "plt.ylabel('Yield')\n",
    "ax = plt.subplot(111)\n",
    "for col in dataTotal.columns:\n",
    "    ax.plot(dataTotal.index,dataTotal.loc[:,col].values,label=col)\n",
    "ax.legend(loc='upper left', bbox_to_anchor=(1, 1), shadow=True, ncol=1)\n",
    "plt.xticks(rotation='vertical')\n",
    "plt.savefig(os.path.join(pathGraficas,'Observed yields'+str(year_t)),bbox_inches='tight')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Modelo Segmentado (Fitted Yield)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#fitSegYields=fitted_yield_NS # Nelson & Siegel Clasico\n",
    "#fitSegYields=fitted_yield_NS_seg_nosmooth # Prefered Habitat\n",
    "#fitSegYields=fitted_yield_NS_seg_weak # Weakly Segmented\n",
    "fitSegYields=fitted_yield_NS_seg_strong #Strongly Segmented"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fitSegYields.index.names = ['Date']\n",
    "plt.ylabel('Yield')\n",
    "ax = plt.subplot(111)\n",
    "for col in fitSegYields.columns:\n",
    "    ax.plot(fitSegYields.index,fitSegYields.loc[:,col].values,label=col)\n",
    "ax.legend(loc='upper left', bbox_to_anchor=(1, 1), shadow=True, ncol=1)\n",
    "plt.xticks(rotation='vertical')\n",
    "plt.savefig(os.path.join(pathGraficas,'Fitted yields'+str(year_t)),bbox_inches='tight')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## RMSE entre NS3 y NS3 Segmented Fitted Yields"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "RMSE_tabl=pd.concat([RMSE_NS3,RMSE_NS3_seg_nosmooth,RMSE_NS3_seg_smooth,RMSE_NS3_seg_smooth_s],axis=1)\n",
    "RMSE_tabl.columns= ['NS3', 'NS3_S', 'NS3_W_S','NS3_S_S'] \n",
    "RMSE_tabl.index.names = ['Maturity']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>NS3</th>\n",
       "      <th>NS3_S</th>\n",
       "      <th>NS3_W_S</th>\n",
       "      <th>NS3_S_S</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Maturity</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0.004</th>\n",
       "      <td>10.150213</td>\n",
       "      <td>288.309186</td>\n",
       "      <td>8.171802</td>\n",
       "      <td>6.637695</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0.1</th>\n",
       "      <td>4.936054</td>\n",
       "      <td>280.942287</td>\n",
       "      <td>3.566604</td>\n",
       "      <td>2.473605</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0.3</th>\n",
       "      <td>6.785276</td>\n",
       "      <td>267.260570</td>\n",
       "      <td>6.911464</td>\n",
       "      <td>7.054699</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1.5</th>\n",
       "      <td>9.018017</td>\n",
       "      <td>213.716417</td>\n",
       "      <td>9.218351</td>\n",
       "      <td>7.905472</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3.8</th>\n",
       "      <td>14.270797</td>\n",
       "      <td>109.032334</td>\n",
       "      <td>17.618629</td>\n",
       "      <td>9.234757</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3.9</th>\n",
       "      <td>19.506343</td>\n",
       "      <td>138.950412</td>\n",
       "      <td>16.033649</td>\n",
       "      <td>24.336000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4.7</th>\n",
       "      <td>9.888137</td>\n",
       "      <td>103.324105</td>\n",
       "      <td>8.034151</td>\n",
       "      <td>9.906447</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5.6</th>\n",
       "      <td>5.554465</td>\n",
       "      <td>68.570888</td>\n",
       "      <td>5.505241</td>\n",
       "      <td>7.222019</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7.3</th>\n",
       "      <td>11.732598</td>\n",
       "      <td>30.845540</td>\n",
       "      <td>3.290812</td>\n",
       "      <td>17.792653</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9.6</th>\n",
       "      <td>10.205713</td>\n",
       "      <td>1.189028</td>\n",
       "      <td>7.299134</td>\n",
       "      <td>7.950087</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11.7</th>\n",
       "      <td>7.115756</td>\n",
       "      <td>4.468408</td>\n",
       "      <td>10.283586</td>\n",
       "      <td>5.628217</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13.3</th>\n",
       "      <td>9.556224</td>\n",
       "      <td>4.432562</td>\n",
       "      <td>6.585754</td>\n",
       "      <td>5.924363</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15.7</th>\n",
       "      <td>9.119949</td>\n",
       "      <td>1.153182</td>\n",
       "      <td>11.247590</td>\n",
       "      <td>12.460853</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                NS3       NS3_S    NS3_W_S    NS3_S_S\n",
       "Maturity                                             \n",
       "0.004     10.150213  288.309186   8.171802   6.637695\n",
       "0.1        4.936054  280.942287   3.566604   2.473605\n",
       "0.3        6.785276  267.260570   6.911464   7.054699\n",
       "1.5        9.018017  213.716417   9.218351   7.905472\n",
       "3.8       14.270797  109.032334  17.618629   9.234757\n",
       "3.9       19.506343  138.950412  16.033649  24.336000\n",
       "4.7        9.888137  103.324105   8.034151   9.906447\n",
       "5.6        5.554465   68.570888   5.505241   7.222019\n",
       "7.3       11.732598   30.845540   3.290812  17.792653\n",
       "9.6       10.205713    1.189028   7.299134   7.950087\n",
       "11.7       7.115756    4.468408  10.283586   5.628217\n",
       "13.3       9.556224    4.432562   6.585754   5.924363\n",
       "15.7       9.119949    1.153182  11.247590  12.460853"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "RMSE_tabl"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "RMSE_tabl.to_latex(index=False,bold_rows=True ,buf=os.path.join(pathTables,'RMSEInSample'+str(year_t)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Export betas for out-of-sample exercise keep only\n",
    "#best performing in-sample: NS3 and NS3_S_S\n",
    "betas_NS.to_csv(os.path.join(pathBases,'NS_'+str(year_t)+'.csv'), sep='|') # NS Classic Model\n",
    "betas_NS_seg_smooth_s.to_csv(os.path.join(pathBases,'NS_S_'+str(year_t)+'.csv'), sep='|') # Strongly Segmented NS Model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Out-of-Sample Forecasting for current year "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Preparations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from statsmodels.tsa.arima_model import ARIMA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Import estimated betas from prevoius year\n",
    "# Use only best perfoming models\n",
    "#Nelson and Siegel Classic\n",
    "betas_NS_Y_1 = pd.read_csv(os.path.join(pathBases,'NS_'+str(year_t_1)+'.csv'), sep='|',index_col=['Fecha'], parse_dates=True)\n",
    "# Strongly Segmented NS Model\n",
    "betas_NS_seg_Y_1 = pd.read_csv(os.path.join(pathBases,'NS_S_'+str(year_t_1)+'.csv'), sep='|',index_col=['Fecha'], parse_dates=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Factor Loadings NS Clasic\n",
    "gNS = g(np.array(vencimientos))\n",
    "hNS = h(np.array(vencimientos)) \n",
    "X = pd.DataFrame({'x1':np.ones_like(gNS),'x2':gNS,'x3':hNS}).values\n",
    "#Factor Loadings NS Segmented\n",
    "Z = W1 - (W2 * R1_invertida * R2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Out-of-Sample Forecasting (Rolling) choose only one of the models below"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Nelson and Siegel Classic\n",
    "#Betas of previous year\n",
    "betas_t_1=betas_NS_Y_1  \n",
    "#Betas of current year\n",
    "#Nelson and Siegel Classic\n",
    "betas_t=betas_NS\n",
    "# append\n",
    "betas_FS=betas_t_1.append(betas_t)\n",
    "#Type of model for forecasting functions\n",
    "NS_model=0 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Strongly Segmented NS Model\n",
    "#Betas of previous year\n",
    "betas_t_1=betas_NS_seg_Y_1 \n",
    "#Betas of current year\n",
    "betas_t=betas_NS_seg_smooth_s\n",
    "#append\n",
    "betas_FS=betas_t_1.append(betas_t)\n",
    "#Type of model for forecasting functions\n",
    "NS_model=1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Define Estimation and evaluation window\n",
    "lastObs_t_1=betas_t_1.shape[0]-1\n",
    "WE=126 # estimation window (aprox 6 months of trading days)\n",
    "WT=betas_t.shape[0]  #evaluation window\n",
    "#Forecast horizon\n",
    "horizon=21 #1 day, 5 days (week), 21 days (month), 63 days (3 months)\n",
    "#Forecast Sample\n",
    "betas_FS=betas_FS.iloc[((lastObs_t_1)-(WE-1)):,:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def NS_yields_fore(Yields,betasS,horizon,WE,X,Z,NS_model):\n",
    "    ErrEW = pd.DataFrame(columns=Yields.columns)\n",
    "    for i in range(0,(Yields.shape[0]-horizon)):\n",
    "        data=betasS.iloc[(0+i):(WE+i),:]\n",
    "        betasout=pd.DataFrame(index=Yields.index[i:i+horizon],columns=data.columns)\n",
    "        ObsYields=Yields.iloc[i:i+horizon,:]\n",
    "        for col in data.columns:\n",
    "            model = ARIMA(data.loc[:,col].values, order=(1,0,0))\n",
    "            model_fit = model.fit(disp=0)\n",
    "            betasout.loc[:,col]=model_fit.forecast(steps=horizon)[0]\n",
    "        if NS_model==0:\n",
    "            fitted_yield = pd.DataFrame(np.dot(X,betasout.values.transpose()).transpose(), index=ObsYields.index,columns=Yields.columns)\n",
    "        else:\n",
    "            fitted_yield = pd.DataFrame(np.dot(Z,betasout.iloc[:,5:].values.transpose()).transpose(), index=ObsYields.index,columns=Yields.columns)\n",
    "        Err_yield=pd.DataFrame(ObsYields.values - fitted_yield.values, index=ObsYields.index,columns=Yields.columns)\n",
    "        ErrEW=ErrEW.append(Err_yield.iloc[(horizon-1),:])\n",
    "    return ErrEW"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ErrEW=NS_yields_fore(dataTotal,betas_FS,horizon,WE,X,Z,NS_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#RMSE\n",
    "RMSE=np.sqrt(ErrEW.apply(lambda x: x**2).mean())\n",
    "RMSE.to_csv(os.path.join(pathForec,'RMSE_'+str(NS_model)+'_H'+str(horizon)+'_'+str(year_t)+'.csv'), sep=';') "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Benchmark Forecast with Random Walk Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Nelson and Siegel Classic or Strongly Segmented NS Model\n",
    "#Betas of random walk\n",
    "betas_RW_t=betas_t.shift(periods=horizon)  \n",
    "#Betas of current year: betas_t\n",
    "#Type of model for forecasting functions: NS_model=0 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def NS_yields_RW(Yields,betasRW,X,Z,NS_model):\n",
    "    if NS_model==0:\n",
    "        fitted_yield = pd.DataFrame(np.dot(X,betasRW.values.transpose()).transpose(), index=Yields.index,columns=Yields.columns)\n",
    "    else:\n",
    "        fitted_yield = pd.DataFrame(np.dot(Z,betaRW.iloc[:,5:].values.transpose()).transpose(), index=Yields.index,columns=Yields.columns)\n",
    "    Err_yield=pd.DataFrame(Yields.values - fitted_yield.values, index=Yields.index,columns=Yields.columns)\n",
    "    return Err_yield"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "ErrRW=NS_yields_RW(dataTotal,betas_RW_t,X,Z,NS_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#RMSE\n",
    "RMSE_RW=np.sqrt(ErrRW.apply(lambda x: x**2).mean())\n",
    "RMSE_RW.to_csv(os.path.join(pathForec,'RMSE_RW_H'+str(horizon)+'_'+str(year_t)+'.csv'), sep=';') "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  },
  "nbTranslate": {
   "displayLangs": [
    "*"
   ],
   "hotkey": "alt-t",
   "langInMainMenu": true,
   "sourceLang": "en",
   "targetLang": "fr",
   "useGoogleTranslate": true
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
